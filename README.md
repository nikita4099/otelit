# ML System Design Doc - Остап Бендер v0.1 [RU]
## Дизайн ML системы - Отелит Подбор Арендатора №1

*Шаблон ML System Design Doc от телеграм-канала [Reliable ML](https://t.me/reliable_ml)*   

- Рекомендации по процессу заполнения документа (workflow) - [здесь](https://github.com/IrinaGoloshchapova/ml_system_design_doc_ru/blob/main/ML_System_Design_Doc_Workflow.md).  
- Детальный доклад о том, что такое ML System Design Doc и о том, как, когда и зачем его составлять - **будет туть**.
    
> ## Термины и пояснения
> - Итерация - это все работы, которые совершаются до старта очередного пилота  
> - БТ - бизнес-требования 
> - EDA - Exploratory Data Analysis - исследовательский анализ данных  
> - `Product Owner`,  `Data Scientist` - роли, которые заполняют соответствующие разделы 
> - В этом шаблоне роль `Data Scientist` совмещает в себе компетенции классического `Data Scientist` с упором на исследования и `ML Engineer` & `ML Ops` роли с акцентом на продуктивизацию моделей
> - Для вашей организации распределение ролей может быть уточнено в зависимости от операционной модели 

### 1. Цели и предпосылки 
#### 1.1. Зачем идем в разработку продукта?  

- Бизнес-цель `Product Owner`: увеличить среднюю конверсию из лида в сделку для арендаторов
- Почему станет лучше, чем сейчас, от использования `Product Owner`,  `Data Scientist`:  система сможет прогнозировать сделку лучше, чем это делает человек, так как может анализировать сотни свободных помещений под конкретный запрос клиента, вместо топ 5-7 самых востребованных у менеджера в моменте  
- Что будем считать успехом итерации с точки зрения бизнеса `Product Owner`: рост конверсии из лида в сделку до 4-5% (Сейчас 2-3).  

#### 1.2. Бизнес-требования и ограничения  

- Краткое описание БТ и ссылки на детальные документы с бизнес-требованиями `Product Owner`: [бизнес-требования](https://github.com/nikita4099/otelit/blob/main/Бизнес-требования) 
**Ира: Вероятно, можно перенести прямо сюда текст бизнес-требований, поскольку он не очень большой** Думаю, что бизнес требования еще не до конца раскрыты, так что пока не буду.
- Бизнес-ограничения `Product Owner` : [бизнес ограничения](https://github.com/nikita4099/otelit/blob/main/Бизнес%20ограничения). **Ира: Есть ли данные для обучения модели и достаточно ли их?** Я описал этот момент, но забыл ссылку вставить. Сейчас вставил
- Что мы ожидаем от конкретной итерации `Product Owner` : проверка данных, построение модели на локальной машине на скаченных данных. Уточнение признаков, метрик и их целевых значение. 
- Описание бизнес-процесса пилота, насколько это возможно - как именно мы будем использовать модель в существующем бизнес-процессе? `Product Owner`:  Машинное обучение работает по принципу запрос-ответ. Из CRM системы поступает запрос с данными о клиенте (признаками для предикта). В ответ система выдаёт ответ 
ответ с номерами айди товаров которые на её взгляд приведут к сделке у данного менеджера с данным клиентом. Шаг 1. Убрать всё не подходящее. Шаг 2. Ранжировать подходящее. Шаг 3. Дать вводные по цене и вероятности. 
- Что считаем успешным пилотом? Критерии успеха и возможные пути развития проекта `Product Owner`: успешной будет модель, которая предлагает убирает заведомо не подходящие варианты. Далее собираем фидбек от менеджеров по аренде. С учётом их вкуса и изменений в конверсии масштабируем систему: добавляем свойства в клиента, персонализируем подбор под лог подбора конкретного менеджера, добавляем информацию помимо айди товара.

#### 1.3. Что входит в скоуп проекта/итерации, что не входит   

- На закрытие каких БТ подписываемся в данной итерации `Data Scientist`: проверка работоспособности модели на имеющихся данных в юпитере на локальной машине без выкатывания в прод или развертывания бэка на сервере. Собираем данные, обрабатываем, обучаем модели, смотрим результат.
- Что не будет закрыто `Data Scientist`: не понятно **Ира: если для этой итерации совпадают ожидания Product Owner и Data Scientist, то пункт просто удаляем. Я только могу предположить, что если завершением этой итерации считаем просто модель, способную вынести предикт, то в этой итерации не будет закрыто требование успеха проекта - повышение конверсии, поскольку мы это пока не измеряем.** Во-первых, владелец продукта и дата саентист это я в одном лице. У меня пока нет проблем с расхождением ожиданий =) Касаемо конверсии. Тут не так просто. Мы можем посчитать изменение конверсии, в этом нет проблемы. Я да, похоже сам себе противоречу. Мерить будем конверсию в сделку, это адекватная оцена бизнес результата. Не будет роста, мы получим прикольную, но бессмысленную МЛ. Касаемо того, что не будет закрыто на данной итерации: Пока не выкатываем в рабочий кластер. Не определяем нужный стэк и ресурсы. Не занимаемся настройкой фронта на строне б24.
- Описание результата с точки зрения качества кода и воспроизводимости решения `Data Scientist` : в данный момент рабочая тетрадь юпитера, в котором подняты первичные данные и сделана МЛ, способная делать предикты для новых клиентов. Внутри комментарии касаемо сделанных шагов и того, что нужно сделать для безотказной работы.
- Описание планируемого технического долга (что оставляем для дальнейшей продуктивизации) `Data Scientist` : настройка пайплайна, версирование моделей и данных. Описать ограничения и требования. Определить стэк.

#### 1.4. Предпосылки решения  

- Описание всех общих предпосылок решения, используемых в системе – с обоснованием от запроса бизнеса: какие блоки данных используем, горизонт прогноза, гранулярность модели, и др. `Data Scientist` : пример бы. **Ира: здесь можно описать ожидания по тому, какие знания о клиенте используем (это блоки данных, в целом, у вас все ниже в таблице описано), горизонт прогноза - ближайшая сделка (либо просто пропустить, у вас задача классификации), гранулярность: клиент - сделка**  Используем признаки описанные выше. Горзонтом прогноза выступает сделка. Гранулярность: клиент-товар-сделка.

### 2. Методология `Data Scientist`     

#### 2.1. Постановка задачи  

- Что делаем с технической точки зрения: рекомендательная система, поиск аномалий, прогноз, оптимизация, и др. `Data Scientist` : в первой итерации MPV - это задача классификации. В последующем рекомендательная система.

#### 2.2. Блок-схема решения  

- Блок-схема для бейзлайна и основного MVP с ключевыми этапами решения задачи: подготовка данных, построение прогнозных моделей, оптимизация, тестирование, закрытие технического долга, подготовка пилота, другое. `Data Scientist`: подготовка данных. **Ира: тут не поняла, видимо, еще нет блок-схемы решения**. Да, пока не могу отрисовать полный цикл.
- [Пример возможной блок схемы](https://github.com/IrinaGoloshchapova/ml_system_design_doc_ru/blob/main/product_schema.png?raw=true)
> Схема обязательно включает в себя архитектуру бейзлайна. Если бейзлайн и основной MVP отличаются несущественно, то это может быть одна блок-схема. Если значительно, то рисуем две: отдельно для бейзлайна, отдельно для основного MVP.  
> Если блок-схема **шаблонна** - т.е. её можно скопировать и применить к разным продуктам, то она **некорректна**. Блок-схема должна показывать схему решения для конкретной задачи, поставленной в части 1.    

#### 2.3. Этапы решения задачи `Data Scientist`  

- Для каждого этапа **по результатам EDA** описываем - **отдельно для бейзлайна** и **отдельно для основного MVP** - все про данные и технику решения максимально конкретно. Обозначаем необходимые вводные, технику предполагаемого решения и что ожидаем получить на выходе, чтобы перейти к следующему этапу.  
- Как правило, детальное и структурированное заполнение раздела `2.3` возможно только **по результатам EDA**.  
- Если описание в дизайн доке **шаблонно** - т.е. его можно скопировать и применить к разным продуктам, то оно **некорректно**. Дизайн док должен показывать схему решения для конкретной задачи, поставленной в части 1.  
    
> Примеры этапов:  
> - Этап 2 - Подготовка прогнозных моделей  
> - Этап 3 - Интерпретация моделей (согл. с заказчиком)  
> - Этап 4 - Интеграция бизнес правил для расчета бизнес-метрик качества мрдели  
> - Этап 5 - Подготовка инференса модели по итерациям    
> - Этап 6 - Интеграция бизнес правил  
> - Этап 7 - Разработка оптимизатора (выбор оптимальной итерации)  
> - Этап 8 - Подготовка финального отчета для бизнеса  

*Этап 1 - это обычно, подготовка данных.*  

В этом этапе должно быть следующее:  

- Данные и сущности, на которых будет обучаться ваша модель машинного обучения. Отдельная таблица для целевой переменной (либо целевых переменных разных этапов), отдельная таблица – для признаков. [Признаки](https://github.com/nikita4099/otelit/blob/main/Признаки%20для%20Остапа) В отдельную страницу вынес этот блок, как бизнес-требования и бизнес-ограничения. Признаки на первых итерациях у меня уже раза 3 менялись и информации, которая описана в этом документе не уверен, что достаточно.
 
- Краткое описание результата этапа - что должно быть на выходе: витрины данных, потоки данных, др. : не понятно **Ира: в вашем случае, если я правильно понимаю - витрины данных для модели** Допустим =) Тоже бы ликбез провести, чем витрины данных от потоков отличаются и какие есть еще варианты.
  
> Чаще всего заполнение раздела невозможно без EDA.

 *Этапы 2 и далее, помимо подготовки данных.*
 
*Этап 2. Обработка данных*
В первую очередь берём те сделки, в которых есть лиды и товары со всеми заполненными полями. Смотрим количество и дисбаланс классов. Если сделок мало, то уменьшаем количество полей из-за которых удаляли сделки. Проверяем на дисбаланс классов. **Ира: тут может быть полезно написать, как именно проверяете и какой дисбаланс считаете для себя приемлемым, чтобы продолжать работу** Критерием определения достаточности числа будет качество модели. Дисбаланс планировал смотреть для того, чтобы понимать, как с ним работать. Сейчас успешные к неуспешным сделкам 1/5. У нас нет требований в бизнес-процессах как-то тщательней заполнять карточку клиента или товар в зависимости от успешности или не успешности сделки. Поэтому ожидаем, что в результате обработки данных отношение успешных к неуспешным останется в этом же отношении. Проблемы будут в будущем. Сейчас сделки заводят сильно меньше, чем по факту их имеют. Поэтому при выкатывании в прод бизнес-процесс можем заменить и дисбаланс будет сильно меняться. Реальный уровень это в районе 1/20 - 1/30. Бороться с ним будем внедрением дополнительных данных из действующих договор аренды. Один оплаченный договор аренды это + 1 успешная сделка. Но это опять же забегая вперёд.

Проводим обработку данных так, чтобы на них можно было обучать модель и данным можно было доверять: тут конкретику распишу уже по ходу обработки. **Ира: это ок. Детализация документа всегда идет на ваше усмотрение. Главное, чтобы он был для вас полезен - для понимания реализуемости задачи, ключевых этапов решения, ожиданий от результата и итоговой отрисовки роадмапа.** Сейчас конкретику расписываю в тетрадке юпитера. Как будет закончены итерации по обработке данных - обучение моделей - доработка данных - доработка моделей, тогда перенесу сюда, скорей всего в отдельную страницу, как требования по обработке данных.

*Этап 3. Проверка моделей*
 
В ходе тестирования нужно определить несколько моделей с метриками лучше, чем модель с рандомным результатом. Также подбираем значение гиперпараметров, при котором метрики будут максимальными. 
 
Описание техники **для каждого этапа** должно включать описание **отдельно для MVP** и **отдельно для бейзлайна**:  

- Описание формирования выборки для обучения, тестирования и валидации. Выбор репрезентативных данных для экспериментов, обучения и подготовки пилота (от бизнес-цели и репрезентативности данных с технической точки зрения) `Data Scientist`: за основу берутся сделки, с подкреплённым товаром и заполненными признаками лида. Так как данные накопленные за разный промежуток времени, часть сделок уже не актуальна, то для пилота данные перемешаем и запустим трейн на 75% с кросс-валидацией на 5 батчах. Оставшиеся 25% будем использовать для тестирования. Идея заключается в том, что решение модели будет использоваться не для прогнозирования сделок, а для прогнозирования провалов. В этом ключе проверку модели в бою можно будет провести довольно быстро. Использовать лиды сегодняшнего дня и экспертно проверить, насколько хорошо или прекрасно модель определила злокачественные варианты. Если качество будет слабым, то проверяем данные уже тщательно и повторяем процедуру.
- Горизонт, гранулярность, частоту необходимого пересчета прогнозных моделей `Data Scientist`: не понятно **Ира: у вас выше описано. Работа модели по запросу. Гранулярность - клиент, сделка. Думаю, стоит дописать требуемую актуальность данных для расчета и требуемую частоту переобучения модели - как часто нужно/хотелось бы ее обновлять** Горизонт - сделка. Гранулярность: клиент-товар-сделка. Пересчёт показателей делать раз в месяц, так как бизнес-цикл происходит на этом промежутке. 
- Определение целевой переменной, согласованное с бизнесом `Data Scientist` : Целевая - Успешная сделка.
- Какие метрики качества используем и почему они связаны с бизнес-результатом, обозначенным `Product Owner` в разделах `1` и `3`. Пример - WAPE <= 50% для > 80% категорий, bias ~ 0. Возможна формулировка в терминах относительно бейзлайна, количественно. Для бейзлайна могут быть свои целевые метрики, а может их вообще не быть (если это обосновано) `Data Scientist`: не понятно **Ира: у вас задача классификации. Для нее существуют различные метрики качества. В какие метрики качества целимся? На какие из них смотрим наиболее пристально. В том числе, с учетом ожидаемого дисбаланса классов. Заполняется ML-специалистом, как правило.** recall =0.8. У нас имеется больше 100 предложений. Для каждого клиента они не подходят. Для самого универсального клиента список предложений может доходить до 10-15 помещений. Поэтому больше 70 строк - это шум, который нам надо убрать. После его убирания менеджеру сложней упустить что-то хорошее и подходящее клиенту, по этой причине он будет предлагать больше помещений, а значит с большей вероятностью заключит сделку с конкретным клиентом. Таким образом конверсия должна вырасти.
- Необходимый результат этапа. Например, необходимым результатом может быть не просто достижение каких-либо метрик качества, а включение в модели определенных факторов (флаг промо для прогноза выручки, др.) `Data Scientist`: понять, в какую сторону идти - реализация в прод или проработка архитектуры и улучшения данных. **Ира: здесь имеется в виду подобное описание для каждого этапа. Например. Этап 1: Собрали данные, проверили качество данных, проверили достаточность данных для построения модели и отсутствие дисбаланса классов - как проверили, как поняли, что можем идти к этапу 2? Этап 2: Построили модель, проверили качество и, например, отсутствие аномальных предсказаний для VIP-клиентов. Тогда понимаем, что можем идти к этапу 3. Этап 3, например, интерпретация модели - копаем, а как именно наша модель принимает решения. И.т.д.** Этап 1. Собрали данные, проверяем их качество. То, что должно быть количественным - количественное, что должно быть качественным - качественное. У количественных метрик пороги похожи на настоящие. У качественных значения соответствуют определенному словарю. Если всё ок, переходим к следующему этапу. Этап 2. Дозаполнение данных. В данных много пропуков. Площади можно заполнять опираясь на соотношение максимального искомой площади к минимальной площади. Также можно проверить в рамках определенного бизнеса. Выбросы исправить, либо убрать. Скооперировать значения по бюджету и бизнесу арендатора из нескольких полей. В товарах проверить компанию-арендатора и заполнение его бизнеса. Задача поднять % сделок, которые попадут в МЛ. (порог не могу назвать пока) Этап 3. Готовим несколько моделей, смотрим результаты. (пока дальше не скажу) 
- Какие могут быть риски и что планируем с этим делать. Например, необходимый для модели фактор (флаг промо) окажется незначимым для большинства моделей. Или для 50% моделей будет недостаточно данных для оценки `Data Scientist`: данные хреново заполнены - будем привлекать практикатов для разметки данных. Результат неоднозначный: то, что должно точно остаться - убыло, то, что должно было точно убыть - осталось. **Ира: здесь снова возвращаемся к вопросу о том, что нужно детальнее прописать/определить для себя алгоритм - как будем понимать достаточность данных** С этим есть сложность. Эта информация в границах "не знаю то, что не знаю". Скорей всего конкретные значения будут в процессе реализации. То есть нужно получить начальный результат и после этого скажу, какой он должен быть. Есть еще риск, что из-за того, что обучение будет делаться для лидов на ретроспективных данных, а на товарах текущего дня - это может запутать систему. Тут либо убирать данные о том, каким бизнесом занимается арендатор на сегодня в товаре, либо поднимать как-то данные ретроспективные по товарам и запускать модель учиться со старого периода к текущему дню.  
- Верхнеуровневые принципы и обоснования для: feature engineering, подбора алгоритма решения, техники кросс-валидации, интерпретации результата (если применимо). Интерпретацию результатов можно провести. Я постарался подобрать наиболее значимые признаки, но даже они между собой имеют разный вес. 
- Предусмотрена ли бизнес-проверка результата этапа и как будет проводиться `Data Scientist` & `Product Owner` : проверка Дмитрием модели, бизнес-проверка мной качества подбора на конкретике.
  
### 3. Подготовка пилота  
  
#### 3.1. Способ оценки пилота  
  
- Краткое описание предполагаемого дизайна и способа оценки пилота `Product Owner`, `Data Scientist` with `AB Group`: отправляем модели батчи из одного лида и всех свободных помещений (Лид-Товар1, Лид-Товар2, Лид-Товар3 и т.д.) и получаем предикты по тому будет ли сделка или нет. Там, где на её взгляд будет - оставляем в подборе. Где точно не будет - убираем.

В будущем: вместо старого "подбора" у менеджера появится всплывающее окно: В нём по умолчанию показывается доска свободных помещений + поле для наполнения товарами, классифициорованных системой как ведущих к сделке. При открытии окна данные о клиенте отправляются в модель. Модель отправляет айди товаров, подходящих клиенту, в интерфесе эти айди открываются в заданном формате. Успешным пиломо будет **Ира: тут не дописано вроде**
  
#### 3.2. Что считаем успешным пилотом  
  
Формализованные в пилоте метрики оценки успешности `Product Owner`: recall = 0.8 **Ира: это на каких данных? На тестовых? Только recall? А при обучении модели на какие метрики смотрим?**  Для пилота проверяем результаты на примере лидов последней неделе. Запускаем и проверяем, сколько товаров очевидных система убрала не верно. Если в 8 из 10 лидов не будет потерь подходящих помещений, то модель считаем успешной.
  
#### 3.3. Подготовка пилота  
  
- Что можем позволить себе, исходя из ожидаемых затрат на вычисления. Если исходно просчитать сложно, то описываем этап расчетов ожидаемой вычислительной сложности на эксперименте с бейзлайном. И предусматриваем уточнение параметров пилота и установку ограничений по вычислительной сложности моделей. `Data Scientist` : хороший вопрос, пока не делал этого, но понимаю о чём речь. В целом, сделок всего 6000. Заполняемость полей в районе 30%. Даже если считать, что у лидов со сделками этот процент выше, то наврядли он будет выше 85%. 5100 будет строк максиму. На каждую по 17 признаков. 86700 признаков.

### 4. Внедрение `для production систем, если требуется`    

> Заполнение раздела 4 требуется не для всех дизайн документов. В некоторых случаях результатом итерации может быть расчет каких-то значений, далее используемых в бизнес-процессе для пилота.  Тут так и есть **Ира: думаю, пока раздел 4 можно просто удалить из документа. Она будет релевантна для следующей итерации проекта**
  
#### 4.1. Архитектура решения   
  
- Блок схема и пояснения: сервисы, назначения, методы API `Data Scientist` : попробуем на Docker сделать. ML как сервис. Через API запросы идут. Но на данном этапе делаем тетрадку юпитера с импортом данных из csv. 
  
#### 4.2. Описание инфраструктуры и масштабируемости 
  
- Какая инфраструктура выбрана и почему `Data Scientist`: надо изучить варианты. Пока никакая
- Плюсы и минусы выбора `Data Scientist` : - 
- Почему финальный выбор лучше других альтернатив `Data Scientist` : - 
  
#### 4.3. Требования к работе системы  
  
- SLA, пропускная способность и задержка `Data Scientist`  : -
  
#### 4.4. Безопасность системы  
  
- Потенциальная уязвимость системы `Data Scientist`  : тут могу сказать, что всё может не заработать из-за того, что данные очень растянуты по времени и в идеале обучение делать не на старых данных, а на срезе данных. Какие были помещения в момент заключения сделки кроме сданного помещения. С точки зрения используемого программного обеспечения или устарения данных, то риски пока оценить сложно, да и возможно не нужно.
  
#### 4.5. Безопасность данных   
  
- Нет ли нарушений GDPR и других законов `Data Scientist`  : нет
  
#### 4.6. Издержки  
  
- Расчетные издержки на работу системы в месяц `Data Scientist` : минимальные. Если используем только открытый код, то кластер у нас есть, его ресурсов должно хватать для пилота
  
#### 4.5. Integration points  
  
- Описание взаимодействия между сервисами (методы API и др.) `Data Scientist` : пока не известно
  
#### 4.6. Риски  
  
- Описание рисков и неопределенностей, которые стоит предусмотреть `Data Scientist` : пока не известно
  
> ### Материалы для дополнительного погружения в тему  
> - [Шаблон ML System Design Doc [EN] от AWS](https://github.com/eugeneyan/ml-design-docs) и [статья](https://eugeneyan.com/writing/ml-design-docs/) с объяснением каждого раздела  
> - [Верхнеуровневый шаблон ML System Design Doc от Google](https://towardsdatascience.com/the-undeniable-importance-of-design-docs-to-data-scientists-421132561f3c) и [описание общих принципов его заполнения](https://towardsdatascience.com/understanding-design-docs-principles-for-achieving-data-scientists-53e6d5ad6f7e).
> - [ML Design Template](https://www.mle-interviews.com/ml-design-template) от ML Engineering Interviews  
> - Статья [Design Documents for ML Models](https://medium.com/people-ai-engineering/design-documents-for-ml-models-bbcd30402ff7) на Medium. Верхнеуровневые рекомендации по содержанию дизайн-документа и объяснение, зачем он вообще нужен  
> - [Краткий Canvas для ML-проекта от Made with ML](https://madewithml.com/courses/mlops/design/#timeline). Подходит для верхнеуровневого описания идеи, чтобы понять, имеет ли смысл идти дальше.  
